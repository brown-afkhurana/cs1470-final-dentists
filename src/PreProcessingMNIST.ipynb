{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "#reshape to 32,32 the same way we do in HW6 \n",
    "#duplicate last axis to R,G,B but have them be all the same color since black and white\n",
    "#push\n",
    "\n",
    "def get_data_MNIST(subset, data_path=\"../data\"):\n",
    "\n",
    "    ## http://yann.lecun.com/exdb/mnist/\n",
    "    subset = subset.lower().strip()\n",
    "    assert subset in (\"test\", \"train\"), f\"unknown data subset {subset} requested\"\n",
    "    inputs_file_path, labels_file_path, num_examples = {\n",
    "        \"train\": (\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\", 60000),\n",
    "        \"test\": (\"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\", 10000),\n",
    "    }[subset]\n",
    "    inputs_file_path = f\"{data_path}/mnist/{inputs_file_path}\"\n",
    "    labels_file_path = f\"{data_path}/mnist/{labels_file_path}\"\n",
    "\n",
    "\n",
    "    ##Declare image variable\n",
    "    image = []\n",
    "\n",
    "    with open(inputs_file_path, 'rb') as f, gzip.GzipFile(fileobj=f) as bytestream: \n",
    "        ##trash (headers ignore)\n",
    "        header = bytestream.read(16)\n",
    "        ##actual image (num exmaple bytes )\n",
    " \n",
    "        ##convert to np.uint8\n",
    "\n",
    "        image_to_shape = np.frombuffer(bytestream.read(), np.uint8)\n",
    "        image_casted = []\n",
    "        for i in image_to_shape: \n",
    "            image_casted.append(np.float32(i)) \n",
    "\n",
    "        new_list= [x/255.0 for x in image_casted]\n",
    "            \n",
    "        image = np.reshape(new_list, (num_examples,784))\n",
    "\n",
    "\n",
    "        #image_nonnormalized = np.frombuffer(bytestream.read(), np.uint8)\n",
    "        #image_non_flat = [i/255.0 for i in image_nonnormalized]\n",
    "        #image = np.reshape(np.float32(image_non_flat), (num_examples,784))\n",
    "    \n",
    "\n",
    "    label = []\n",
    "\n",
    "    with open(labels_file_path, 'rb') as f, gzip.GzipFile(fileobj=f) as bytestream: \n",
    "        ##trash (headers ignore)\n",
    "        header = bytestream.read(8)\n",
    "\n",
    "        ##actual image (num exmaple bytes )\n",
    "\n",
    "        ##convert to np.uint8\n",
    "        label = np.frombuffer(bytestream.read(), np.uint8)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "#image_train_full, label_train_full = None, None\n",
    "#image_test_full,  label_test_full  = None, None\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_data_CIFAR(subset):\n",
    "    (train_image, train_label), (test_image, test_label) = tf.keras.datasets.cifar10.load_data()\n",
    "    #50,000 training images and 10,000 test images\n",
    "\n",
    "    depth = 10\n",
    "\n",
    "    #image resizing is unecessary, so it is commented out\n",
    "    #RGB values are normalized between 0 and 1\n",
    "    #labels are converted into one hot tensors\n",
    "    if subset == \"train\":\n",
    "        #train_image = tf.expand_dims(train_image, axis=-1)\n",
    "        #train_image = tf.image.resize(train_image, [32,32,3])\n",
    "        image = train_image/255\n",
    "        label = tf.one_hot(train_label, depth)\n",
    "\n",
    "\n",
    "    if subset == \"test\":\n",
    "        #test_image = tf.expand_dims(test_image, axis=-1)\n",
    "        #test_image = tf.image.resize(test_image, [32,32,3])\n",
    "        image = test_image/255\n",
    "        label = tf.one_hot(test_label, depth)\n",
    "\n",
    "    return image, label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "632bfbf88d9ccbc17d9ac727f8e6ee6825b5dd244d80b36af830f75634a39c29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
